{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "cuda2",
      "language": "python",
      "name": "cuda2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "1871095_문수빈_홍채_2차_코드.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "851e51f7"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "id": "851e51f7",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "069a8b95",
        "outputId": "ae73974b-9775-47a6-8956-627e38463998"
      },
      "source": [
        "print(tf.__version__)\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "id": "069a8b95",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF0K8RUrFd5I",
        "outputId": "f626206d-1755-4790-9c09-bb726974b5f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "id": "aF0K8RUrFd5I",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGjlmmBLJmSM"
      },
      "source": [
        "path = '/gdrive/My Drive/'"
      ],
      "id": "DGjlmmBLJmSM",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQTM7tlWP23P"
      },
      "source": [
        ""
      ],
      "id": "RQTM7tlWP23P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkxM3oUBMe6W"
      },
      "source": [
        "<h1> Load Module </h1>"
      ],
      "id": "GkxM3oUBMe6W"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23db36c7"
      },
      "source": [
        "from keras import models, layers, optimizers, utils\n",
        "from keras.layers import Dropout, Activation, Dense, BatchNormalization\n",
        "from keras.models import load_model"
      ],
      "id": "23db36c7",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aca97b7a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img\n",
        "import random\n",
        "import cv2, os, sys\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image"
      ],
      "id": "aca97b7a",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23e5dae5"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
        "from numpy import expand_dims"
      ],
      "id": "23e5dae5",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61136cf5"
      },
      "source": [
        "<h1> Load Image </h1>"
      ],
      "id": "61136cf5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78a2d4e8"
      },
      "source": [
        "# 이미지 크기 지정\n",
        "\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224"
      ],
      "id": "78a2d4e8",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKIb-eN-qbhW"
      },
      "source": [
        "# 트레이닝 데이터 파일을 정렬\n",
        "import natsort\n",
        "train_order = os.listdir(path+'04_multimodal_training')\n",
        "train_order = natsort.natsorted(train_order)"
      ],
      "id": "qKIb-eN-qbhW",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFMa20fwL3aH"
      },
      "source": [
        "# Image Augmentation 생성\n",
        "datagen = ImageDataGenerator(\n",
        "            width_shift_range = 0.01,\n",
        "            height_shift_range = 0.01,\n",
        "            horizontal_flip = True,\n",
        "            vertical_flip = True,\n",
        "            zoom_range = 0.05,\n",
        "            brightness_range=[1.0, 1.0])"
      ],
      "id": "jFMa20fwL3aH",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOUCkg8fIn7z"
      },
      "source": [
        "# 이미지를 64개의 카테고리로 분류\n",
        "nb_classes = 64\n",
        "\n",
        "data = []\n",
        "label= []\n",
        "dtype = []\n",
        "\n",
        "for filename in train_order:\n",
        "    category = filename[:3]\n",
        "    imagePath = path + '/04_multimodal_training/' + filename\n",
        "    if filename[4:8] == 'face':\n",
        "      dtype.append('F')\n",
        "    elif filename[4:8] == 'iris':\n",
        "      dtype.append('I')\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "    \n",
        "    data.append(image)\n",
        "    label.append(int(category))\n",
        "    new_image = img_to_array(image)\n",
        "    samples = expand_dims(new_image, 0)\n",
        "    it= datagen.flow(samples, batch_size=1)\n",
        "\n",
        "    # 이미지를 5개씩 augmentation\n",
        "    for i in range(5):\n",
        "        batch = it.next()\n",
        "        image = batch[0].astype('uint8')\n",
        "        np_image = np.array(image)\n",
        "\n",
        "        data.append(np_image)\n",
        "        label.append(int(category))\n",
        "        \n",
        "        # 이미지의 종류에 따라 타입 설정\n",
        "        if filename[4:8] == 'face':\n",
        "          dtype.append('F')\n",
        "        elif filename[4:8] == 'iris':\n",
        "          dtype.append('I')"
      ],
      "id": "kOUCkg8fIn7z",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f3d7fc5"
      },
      "source": [
        "# iris와 face 각각 훈련데이터셋 형성\n",
        "\n",
        "face_X = []\n",
        "face_Y = []\n",
        "iris_X = []\n",
        "iris_Y = []\n",
        "\n",
        "for i in range((len(data))):\n",
        "  if dtype[i] == 'F':\n",
        "    face_X.append(data[i])\n",
        "    face_Y.append(label[i])\n",
        "  elif dtype[i] == 'I':\n",
        "    iris_X.append(data[i])\n",
        "    iris_Y.append(label[i])"
      ],
      "id": "1f3d7fc5",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFXEjhQ9Oozv"
      },
      "source": [
        "<h1> Build Multimodal Model </h1>"
      ],
      "id": "TFXEjhQ9Oozv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVWWUkz34w35"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras import models, layers, optimizers, utils\n",
        "from keras.layers import Dropout, Activation, Dense\n",
        "from keras.layers import Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.models import load_model"
      ],
      "id": "cVWWUkz34w35",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmYIxH0m3ae3"
      },
      "source": [
        "# CNN 모델 생성\n",
        "\n",
        "def build_model():\n",
        "\n",
        "    learning_rate = 0.0001\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
        "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Convolution2D(2622, (1, 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    return model"
      ],
      "id": "PmYIxH0m3ae3",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jytikPkY3sFa",
        "outputId": "11570f0f-01d2-42d0-c8c8-3ecbab47c5bb"
      },
      "source": [
        "# VGG face 가중치 사용\n",
        "\n",
        "model = build_model()\n",
        "model.load_weights(path+'/vgg_face_weights.h5')\n",
        "model.summary()"
      ],
      "id": "jytikPkY3sFa",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2622)              0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2622)              0         \n",
            "=================================================================\n",
            "Total params: 145,002,878\n",
            "Trainable params: 145,002,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEYOAzTv3vlT"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
      ],
      "id": "DEYOAzTv3vlT",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6219aef"
      },
      "source": [
        "face_X = np.array(face_X)\n",
        "iris_X = np.array(iris_X)\n",
        "face_Y = np.array(face_Y)\n",
        "iris_Y = np.array(iris_Y)"
      ],
      "id": "f6219aef",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVidXCfP4AJV"
      },
      "source": [
        "# 이미지를 64개의 카테고리로 분류\n",
        "nb_classes = 64\n",
        "\n",
        "face_embeddings = np.zeros((nb_classes*24, 2622))\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image in face_X:\n",
        "    image = (image / 255.).astype(np.float32)\n",
        "    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
        "    # descriptor 모델에서 나온 특징점들을 저장\n",
        "    face_embeddings[i]= descriptor.predict(np.expand_dims(image, axis=0))[0]\n",
        "    i += 1"
      ],
      "id": "vVidXCfP4AJV",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqxjXz6GtAg3"
      },
      "source": [
        "# 이미지를 64개의 카테고리로 분류\n",
        "nb_classes = 64\n",
        "\n",
        "iris_embeddings = np.zeros((nb_classes*24, 2622))\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image in iris_X:\n",
        "    image = (image / 255.).astype(np.float32)\n",
        "    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
        "    # face_descriptor 모델에서 나온 특징점들을 저장\n",
        "    iris_embeddings[i]= descriptor.predict(np.expand_dims(image, axis=0))[0]\n",
        "    i += 1"
      ],
      "id": "rqxjXz6GtAg3",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPImJ2gGPSCe"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ],
      "id": "bPImJ2gGPSCe",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnn7aYEWDpVr"
      },
      "source": [
        "# CNN으로 예측한 홍채와 얼굴 특징점 데이터를 하나의 특징으로 합침\n",
        "embeddings = []\n",
        "\n",
        "i = 0\n",
        "for i in range(len(iris_embeddings)):\n",
        "  embeddings.append(face_embeddings[i] + iris_embeddings[i])\n",
        "  i += 1"
      ],
      "id": "Mnn7aYEWDpVr",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_eVg-tuEiEP"
      },
      "source": [
        "embeddings = np.array(embeddings)"
      ],
      "id": "T_eVg-tuEiEP",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CseFMPnaEDbT"
      },
      "source": [
        "# 특징 데이터들을 train과 test로 분할\n",
        "# 4개의 데이터마다 하나씩 테스트 데이터로 사용\n",
        "train_idx = np.arange(nb_classes*24) % 4 != 0\n",
        "test_idx = np.arange(nb_classes*24) % 4 == 0\n",
        "\n",
        "X_train = embeddings[train_idx]\n",
        "X_test = embeddings[test_idx]\n",
        "Y_train = face_Y[train_idx]\n",
        "Y_test = face_Y[test_idx]"
      ],
      "id": "CseFMPnaEDbT",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KbSM5sOQb2m"
      },
      "source": [
        "# y_train과 y_test 값을 라벨링\n",
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(Y_train)\n",
        "Y_test = encoder.transform(Y_test)"
      ],
      "id": "0KbSM5sOQb2m",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SjIbZy9EoDG",
        "outputId": "efca1082-9f81-46e6-e749-6451325394d6"
      },
      "source": [
        "# SVM으로 학습 데이터 훈련\n",
        "svc = LinearSVC(C = 10) \n",
        "svc.fit(X_train, Y_train)\n",
        "y_pred = svc.predict(X_train)\n",
        "\n",
        "# 3번의 cross validation을 통해 training set score 교차 검증\n",
        "print(\"Accuracy on training set: \", cross_val_score(svc, X_train, Y_train, cv=3))\n",
        "print(\"Accuracy on test set: \", svc.score(X_test, Y_test))"
      ],
      "id": "1SjIbZy9EoDG",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set:  [1.         0.99739583 0.9609375 ]\n",
            "Accuracy on test set:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__FytRW9SBc8",
        "outputId": "b9999659-0189-47f9-fd70-1a4833484508"
      },
      "source": [
        "# model accuracy\n",
        "\n",
        "y_test_pred = svc.predict(X_test)\n",
        "\n",
        "print(\"accuracy: {:.2f}\".format(accuracy_score(Y_test, y_test_pred)))\n",
        "print(\"Precision: {:.2f}\".format(precision_score(Y_test, y_test_pred, average = 'micro')))\n",
        "print(\"Recall: {:.2f}\".format(recall_score(Y_test, y_test_pred, average = 'micro')))\n",
        "print(\"F1-score: {:.2f}\".format(f1_score(Y_test, y_test_pred, average = 'micro')))"
      ],
      "id": "__FytRW9SBc8",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2556bc9d"
      },
      "source": [
        "<h1> Test </h1>"
      ],
      "id": "2556bc9d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbDVjvRMh-TL"
      },
      "source": [
        "import pandas as pd"
      ],
      "id": "vbDVjvRMh-TL",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61e4e7e3"
      },
      "source": [
        "# 테스트데이터 파일을 숫자 순으로 정렬\n",
        "import natsort\n",
        "order_list = os.listdir(path+'04_multimodal_test')\n",
        "order_list = natsort.natsorted(order_list)"
      ],
      "id": "61e4e7e3",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTG2okBXqG-H",
        "outputId": "9a0ece97-8424-4834-a574-77e88b6c9d85"
      },
      "source": [
        "print(order_list)"
      ],
      "id": "iTG2okBXqG-H",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0_face.png', '0_iris.png', '1_face.png', '1_iris.png', '2_face.png', '2_iris.png', '3_face.png', '3_iris.png', '4_face.png', '4_iris.png', '5_face.png', '5_iris.png', '6_face.png', '6_iris.png', '7_face.png', '7_iris.png', '8_face.png', '8_iris.png', '9_face.png', '9_iris.png', '10_face.png', '10_iris.png', '11_face.png', '11_iris.png', '12_face.png', '12_iris.png', '13_face.png', '13_iris.png', '14_face.png', '14_iris.png', '15_face.png', '15_iris.png', '16_face.png', '16_iris.png', '17_face.png', '17_iris.png', '18_face.png', '18_iris.png', '19_face.png', '19_iris.png', '20_face.png', '20_iris.png', '21_face.png', '21_iris.png', '22_face.png', '22_iris.png', '23_face.png', '23_iris.png', '24_face.png', '24_iris.png', '25_face.png', '25_iris.png', '26_face.png', '26_iris.png', '27_face.png', '27_iris.png', '28_face.png', '28_iris.png', '29_face.png', '29_iris.png', '30_face.png', '30_iris.png', '31_face.png', '31_iris.png', '32_face.png', '32_iris.png', '33_face.png', '33_iris.png', '34_face.png', '34_iris.png', '35_face.png', '35_iris.png', '36_face.png', '36_iris.png', '37_face.png', '37_iris.png', '38_face.png', '38_iris.png', '39_face.png', '39_iris.png', '40_face.png', '40_iris.png', '41_face.png', '41_iris.png', '42_face.png', '42_iris.png', '43_face.png', '43_iris.png', '44_face.png', '44_iris.png', '45_face.png', '45_iris.png', '46_face.png', '46_iris.png', '47_face.png', '47_iris.png', '48_face.png', '48_iris.png', '49_face.png', '49_iris.png', '50_face.png', '50_iris.png', '51_face.png', '51_iris.png', '52_face.png', '52_iris.png', '53_face.png', '53_iris.png', '54_face.png', '54_iris.png', '55_face.png', '55_iris.png', '56_face.png', '56_iris.png', '57_face.png', '57_iris.png', '58_face.png', '58_iris.png', '59_face.png', '59_iris.png', '60_face.png', '60_iris.png', '61_face.png', '61_iris.png', '62_face.png', '62_iris.png', '63_face.png', '63_iris.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCa1g6-gYg4e"
      },
      "source": [
        "# face와 test 각각 배열에 저장\n",
        "face_test = []\n",
        "iris_test = []\n",
        "\n",
        "for filename in order_list:\n",
        "    imagePath = path + '/04_multimodal_test/' + filename\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "\n",
        "    new_image = (image / 255.).astype(np.float32)\n",
        "    new_image = cv2.resize(new_image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
        "\n",
        "    if filename[-8:-4] == 'face':\n",
        "      face_test.append(face_descriptor.predict(np.expand_dims(new_image, axis=0))[0])\n",
        "    elif filename[-8:-4] == 'iris':\n",
        "      iris_test.append(face_descriptor.predict(np.expand_dims(new_image, axis=0))[0])"
      ],
      "id": "YCa1g6-gYg4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkJPezpmFlnw"
      },
      "source": [
        "face_test = np.array(face_test)\n",
        "iris_test = np.array(iris_test)"
      ],
      "id": "LkJPezpmFlnw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l49zK-VKFUPU"
      },
      "source": [
        "test_embeddings = []\n",
        "\n",
        "i = 0\n",
        "for i in range(len(face_test)):\n",
        "  test_embeddings.append(face_test[i] + iris_test[i])\n",
        "  i += 1"
      ],
      "id": "l49zK-VKFUPU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52TTtIMujQUx"
      },
      "source": [
        "# face model predict\n",
        "predict = svc.predict(test_embeddings)"
      ],
      "id": "52TTtIMujQUx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b0RgwsMuMuF",
        "outputId": "84b654c9-93d6-45e1-ae6f-519864cf3f84"
      },
      "source": [
        "# face model result\n",
        "predict"
      ],
      "id": "3b0RgwsMuMuF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27, 31, 22, 57, 54, 45,  5, 12,  8,  7, 36,  2, 46, 50, 10, 61, 49,\n",
              "       59, 56, 13, 37, 30, 25,  0, 41, 58,  9, 20, 48, 47, 42, 24,  3,  6,\n",
              "       55, 63, 21, 16, 34, 11, 35, 32, 40, 62, 19, 52, 33, 15,  1, 29, 17,\n",
              "       26, 53, 28, 18, 14, 43, 60,  4, 39, 38, 23, 51, 44])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdDHnO3bUZbv"
      },
      "source": [
        "<h1> Result </h1>"
      ],
      "id": "AdDHnO3bUZbv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBjed2RWj_1u"
      },
      "source": [
        "result = pd.DataFrame({'Image':[],\n",
        "                 'Answer':[]})"
      ],
      "id": "HBjed2RWj_1u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPNVh0YZgeTc"
      },
      "source": [
        "for i in range(len(predict)):\n",
        "  new_data = {'Image':int(i), 'Answer':int(predict[i])}\n",
        "  result = result.append(new_data, ignore_index = True)"
      ],
      "id": "JPNVh0YZgeTc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "sobEo3ghi16v",
        "outputId": "faecd732-28d2-452f-831d-50a23020a581"
      },
      "source": [
        "result"
      ],
      "id": "sobEo3ghi16v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62.0</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Image  Answer\n",
              "0     0.0    27.0\n",
              "1     1.0    31.0\n",
              "2     2.0    22.0\n",
              "3     3.0    57.0\n",
              "4     4.0    54.0\n",
              "..    ...     ...\n",
              "59   59.0    39.0\n",
              "60   60.0    38.0\n",
              "61   61.0    23.0\n",
              "62   62.0    51.0\n",
              "63   63.0    44.0\n",
              "\n",
              "[64 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9n-j7hkjK3Y"
      },
      "source": [
        "result.to_csv('/gdrive/My Drive/multimodal_result2.csv')"
      ],
      "id": "W9n-j7hkjK3Y",
      "execution_count": null,
      "outputs": []
    }
  ]
}